spring:
  application:
    name: ollama-chat
  ai:
    ollama:
      chat:
        options:
          model: llama3.1:8b
server:
  port: 7770

spring.profiles.active: local
