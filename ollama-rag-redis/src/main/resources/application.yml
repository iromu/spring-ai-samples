spring:
  application:
    name: ollama-rag-redis
  ai:
    vectorstore:
      redis:
        uri: redis://localhost:9736
        index: ollama-rag-index
        prefix: "ollama-rag:"
        initialize-schema: true
    ollama:
      chat:
        options:
          model: llama3
      embedding:
        model: llama3
  docker:
    compose:
      lifecycle-management: start_only

server:
  port: 7778
