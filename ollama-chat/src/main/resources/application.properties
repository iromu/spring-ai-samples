spring.application.name=ollama-chat
server.port=7777

spring.ai.ollama.chat.options.model=llama3
spring.docker.compose.lifecycle-management=start_only
spring.threads.virtual.enabled=true
