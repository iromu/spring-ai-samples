spring.application.name=ollama-chat
server.port=7777
spring.ai.ollama.chat.options.model=llama3.1:8b
spring.docker.compose.lifecycle-management=start_only
spring.threads.virtual.enabled=true
